{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FKz11/Neural_Network/blob/lesson-4/lesson_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "548eddf6",
      "metadata": {
        "id": "548eddf6"
      },
      "source": [
        "## lesson-4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7514af24",
      "metadata": {
        "id": "7514af24"
      },
      "source": [
        "Библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "720d6e17",
      "metadata": {
        "id": "720d6e17"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.random import set_seed\n",
        "\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "47df28b2",
      "metadata": {
        "id": "47df28b2"
      },
      "outputs": [],
      "source": [
        "classes=['самолет', 'автомобиль', 'птица', 'кот', 'олень', 'собака', 'лягушка', 'лошадь', 'корабль', 'грузовик']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f6a57bb0",
      "metadata": {
        "id": "f6a57bb0"
      },
      "outputs": [],
      "source": [
        "# загрузка тренировочных и тестовых данных\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# конвертация чисел из uint8 в float32\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# нормализация данных [0, 1]\n",
        "x_train /= 255 \n",
        "x_test /= 255 \n",
        "\n",
        "# трансформация лейблов в one-hot encoding\n",
        "y_train = to_categorical(y_train, 10) \n",
        "y_test = to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "774c4de1",
      "metadata": {
        "id": "774c4de1"
      },
      "outputs": [],
      "source": [
        "def nn_conv(x_train, x_test, y_train, y_test, branch = 4, start_filters = 24, start_kernel = 2, \n",
        "                              neurons = 2000, batch_size = 128, epochs = 7, verbose = 1, seed = 42):\n",
        "\n",
        "    set_seed(seed)\n",
        "    \n",
        "    first_layer = np.empty(branch, dtype=object)\n",
        "    \n",
        "    first_input = layers.Input(shape=x_train.shape[1:]) # shape = (32, 32, 3)\n",
        "\n",
        "    for i in range(branch):\n",
        "      if i > 1:                                                                                         \n",
        "        conv = layers.Conv2D(start_filters*2**(i-1),2*(branch-1) + start_kernel - 2*i,                            # filters = 12, 12, 24, 48\n",
        "                                            activation='relu',padding = 'same',name=f'conv_1_{i+1}')(first_input) # kernel_size = 8, 6, 4, 2\n",
        "        first_layer[i] = layers.MaxPool2D(pool_size=(2**(i-1),2**(i-1)),name=f'pool_1_{i+1}')(conv)               # pool_size = 1, 1, 2, 4\n",
        "      else:\n",
        "        first_layer[i] = layers.Conv2D(start_filters,2*(branch-1) + start_kernel - 2*i,\n",
        "                                       activation='relu',padding = 'same',name=f'conv_1_{i+1}')(first_input)\n",
        "\n",
        "    layer_list = first_layer.copy()\n",
        "\n",
        "    for i in range(branch-1):\n",
        "      merge = layers.Concatenate(  axis =-1,name=f'merge_{i+2}' )([layer_list[i], first_layer[i+1]])                                                   \n",
        "      conv = layers.Conv2D(start_filters*2**(i+1),2*(branch-1) + start_kernel - 2*(i+1),   # filters = 24, 48, 96\n",
        "                           activation='relu',padding = 'same',name=f'conv_{i+2}')(merge)   # kernel_size = 6, 4, 2\n",
        "      layer_list[i+1] = layers.MaxPool2D(pool_size=(2,2),name=f'pool_{i+2}')(conv)\n",
        "\n",
        "    flatten = layers.Flatten(name='flatten')(layer_list[branch-1]) # input_shape = (4, 4, 96)\n",
        "    \n",
        "    dense_one=layers.Dense(neurons, activation='relu', name='dense_one')(flatten) # input_shape = (1536)\n",
        "    \n",
        "    dense_two=layers.Dense(y_train.shape[1], activation='softmax', name='dense_two')(dense_one)\n",
        "    \n",
        "    model = Model(inputs=first_input, outputs=dense_two)\n",
        "    \n",
        "    # компиляция модели\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "    \n",
        "    hh = model.fit(x_train, y_train, shuffle=True,\n",
        "                   batch_size=batch_size,\n",
        "                   epochs=epochs,\n",
        "                   verbose=verbose,\n",
        "                   validation_data=(x_test, y_test))\n",
        "    \n",
        "    return model, hh.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bcaeff4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "8bcaeff4",
        "outputId": "e831c437-6e60-47df-b4a5-7f5f0e8c2b82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "391/391 [==============================] - 42s 101ms/step - loss: 1.4674 - accuracy: 0.4691 - val_loss: 1.1182 - val_accuracy: 0.6046\n",
            "Epoch 2/7\n",
            "391/391 [==============================] - 38s 98ms/step - loss: 1.0247 - accuracy: 0.6367 - val_loss: 0.9408 - val_accuracy: 0.6696\n",
            "Epoch 3/7\n",
            "391/391 [==============================] - 38s 97ms/step - loss: 0.8276 - accuracy: 0.7096 - val_loss: 0.8681 - val_accuracy: 0.7033\n",
            "Epoch 4/7\n",
            "391/391 [==============================] - 38s 98ms/step - loss: 0.7018 - accuracy: 0.7539 - val_loss: 0.7921 - val_accuracy: 0.7296\n",
            "Epoch 5/7\n",
            "391/391 [==============================] - 38s 97ms/step - loss: 0.5868 - accuracy: 0.7942 - val_loss: 0.7956 - val_accuracy: 0.7330\n",
            "Epoch 6/7\n",
            "391/391 [==============================] - 38s 98ms/step - loss: 0.4748 - accuracy: 0.8334 - val_loss: 0.7975 - val_accuracy: 0.7431\n",
            "Epoch 7/7\n",
            "356/391 [==========================>...] - ETA: 3s - loss: 0.3628 - accuracy: 0.8721"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-75a6b4d9d766>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model, hh = nn_conv(x_train, x_test, y_train, y_test, branch = 4, start_filters = 24, start_kernel = 2, \n\u001b[0;32m----> 2\u001b[0;31m                                       neurons = 2000, batch_size = 128, epochs = 7, verbose = 1, seed = 42)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-8bc6c0f0394f>\u001b[0m in \u001b[0;36mnn_conv\u001b[0;34m(x_train, x_test, y_train, y_test, branch, start_filters, start_kernel, neurons, batch_size, epochs, verbose, seed)\u001b[0m\n\u001b[1;32m     42\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                    validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model, hh = nn_conv(x_train, x_test, y_train, y_test, branch = 4, start_filters = 24, start_kernel = 2, \n",
        "                                      neurons = 2000, batch_size = 128, epochs = 9, verbose = 1, seed = 42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{key: value[-1] for key, value in hh.items()}"
      ],
      "metadata": {
        "id": "2X5KSOB7y_ys"
      },
      "id": "2X5KSOB7y_ys",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44e18907",
      "metadata": {
        "id": "44e18907"
      },
      "outputs": [],
      "source": [
        "plot_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "lUqvwB7kPLIM"
      },
      "id": "lUqvwB7kPLIM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пускай количество эпох = 10. Итоговой метрикой будем считать лучшую за 10 эпох."
      ],
      "metadata": {
        "id": "q6c9SyWmvV0K"
      },
      "id": "q6c9SyWmvV0K"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### branch"
      ],
      "metadata": {
        "id": "3w49-8VjrhcN"
      },
      "id": "3w49-8VjrhcN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "При увеличении количество веток увилививается как ширина нейронной сети, так и длина. Но так как после каждой свёртке идёт MaxPool с pool_size = (2,2), а начальный размер изображения 32x32, то максимальное количество веток будет 6, причём размеры конечных изображений будут 1x1 с количество фильтров равным start_filters*32."
      ],
      "metadata": {
        "id": "yqFkt0YLsf5b"
      },
      "id": "yqFkt0YLsf5b"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "branch_list = list(range(2, 7))\n",
        "\n",
        "metrics_branch = []\n",
        "\n",
        "for branch in branch_list:\n",
        "  metric = np.max(nn_conv(x_train, x_test, y_train, y_test, branch = branch, start_filters = 24, \n",
        "              start_kernel = 2, neurons = 2000, batch_size = 128, epochs = 10, verbose = 0, seed = 42)[1]['val_accuracy'])\n",
        "  print(f'{branch} - {metric}')\n",
        "  metrics_branch.append(metric)"
      ],
      "metadata": {
        "id": "n47uEZ0Nrf2-"
      },
      "id": "n47uEZ0Nrf2-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(branch_list, metrics_branch, color = 'red')\n",
        "plt.title('NN_accuracy', fontsize=20)\n",
        "plt.xlabel('branch', fontsize=15)\n",
        "plt.ylabel('accuracy', fontsize=15)\n",
        "plt.legend(prop={'size': 15})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vt6e4C9szqni"
      },
      "id": "Vt6e4C9szqni",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Лучшее количество branch = 4, хотя это скорее связано с размерами выходных изображений после MaxPool, которые будут 4x4 с 96 фильтрами."
      ],
      "metadata": {
        "id": "z1gucY1I7rtA"
      },
      "id": "z1gucY1I7rtA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### start_filters"
      ],
      "metadata": {
        "id": "-QqIeth75686"
      },
      "id": "-QqIeth75686"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "start_filters_list = [12, 18, 24, 36, 48]\n",
        "\n",
        "metrics_start_filters = []\n",
        "\n",
        "for start_filters in start_filters_list:\n",
        "  metric = np.max(nn_conv(x_train, x_test, y_train, y_test, branch = 4, start_filters = start_filters, \n",
        "              start_kernel = 2, neurons = 2000, batch_size = 128, epochs = 10, verbose = 0, seed = 42)[1]['val_accuracy'])\n",
        "  print(f'{start_filters} - {metric}')\n",
        "  metrics_start_filters.append(metric)"
      ],
      "metadata": {
        "id": "9fIb5gUo6J8g"
      },
      "id": "9fIb5gUo6J8g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(start_filters_list, metrics_start_filters, color = 'red')\n",
        "plt.title('NN_accuracy', fontsize=20)\n",
        "plt.xlabel('start_filters', fontsize=15)\n",
        "plt.ylabel('accuracy', fontsize=15)\n",
        "plt.legend(prop={'size': 15})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9YISOroI7F92"
      },
      "id": "9YISOroI7F92",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Лучшее количество start_filters = 24."
      ],
      "metadata": {
        "id": "fj01Sp4w94ZV"
      },
      "id": "fj01Sp4w94ZV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### start_kernel"
      ],
      "metadata": {
        "id": "tT4G8ROw80Xn"
      },
      "id": "tT4G8ROw80Xn"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "start_kernel_list = [1, 2, 3, 4, 5]\n",
        "\n",
        "metrics_start_kernel = []\n",
        "\n",
        "for start_kernel in start_kernel_list:\n",
        "  metric = np.max(nn_conv(x_train, x_test, y_train, y_test, branch = 4, start_filters = 24, \n",
        "              start_kernel = start_kernel, neurons = 2000, batch_size = 128, epochs = 10, verbose = 0, seed = 42)[1]['val_accuracy'])\n",
        "  print(f'{start_kernel} - {metric}')\n",
        "  metrics_start_kernel.append(metric)"
      ],
      "metadata": {
        "id": "KgkCN-9x9AJR"
      },
      "id": "KgkCN-9x9AJR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(start_kernel_list, metrics_start_kernel, color = 'red')\n",
        "plt.title('NN_accuracy', fontsize=20)\n",
        "plt.xlabel('start_kernel', fontsize=15)\n",
        "plt.ylabel('accuracy', fontsize=15)\n",
        "plt.legend(prop={'size': 15})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "00ffMg649ZcV"
      },
      "id": "00ffMg649ZcV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Лучшее количество start_kernel = 2, хотя оно и чётное, оно даёт лучшую метрику."
      ],
      "metadata": {
        "id": "qwc4vZIk91pR"
      },
      "id": "qwc4vZIk91pR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### neurons"
      ],
      "metadata": {
        "id": "xSt83_KS95YO"
      },
      "id": "xSt83_KS95YO"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "neurons_list = [1000, 2000, 3000, 5000, 10000]\n",
        "\n",
        "metrics_neurons = []\n",
        "\n",
        "for neurons in neurons_list:\n",
        "  metric = np.max(nn_conv(x_train, x_test, y_train, y_test, branch = 4, start_filters = 24, \n",
        "              start_kernel = 2, neurons = neurons, batch_size = 128, epochs = 10, verbose = 0, seed = 42)[1]['val_accuracy'])\n",
        "  print(f'{neurons} - {metric}')\n",
        "  metrics_neurons.append(metric)"
      ],
      "metadata": {
        "id": "BZo2ON6m98LN"
      },
      "id": "BZo2ON6m98LN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(neurons_list, metrics_neurons, color = 'red')\n",
        "plt.title('NN_accuracy', fontsize=20)\n",
        "plt.xlabel('neurons', fontsize=15)\n",
        "plt.xscale('log')\n",
        "plt.ylabel('accuracy', fontsize=15)\n",
        "plt.legend(prop={'size': 15})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3w8lTQr4-NGa"
      },
      "id": "3w8lTQr4-NGa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Лучшее количество neurons = 2000. При входных данных размером 4x4x24x2^4 = 6144."
      ],
      "metadata": {
        "id": "VR9yzRto-oQk"
      },
      "id": "VR9yzRto-oQk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### batch_size"
      ],
      "metadata": {
        "id": "4ocZvSIq-oaQ"
      },
      "id": "4ocZvSIq-oaQ"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size_list = [32, 64, 128, 256, 512]\n",
        "\n",
        "metrics_batch_size = []\n",
        "\n",
        "for batch_size in batch_size_list:\n",
        "  metric = np.max(nn_conv(x_train, x_test, y_train, y_test, branch = 4, start_filters = 24, \n",
        "              start_kernel = 2, neurons = 2000, batch_size = batch_size, epochs = 10, verbose = 0, seed = 42)[1]['val_accuracy'])\n",
        "  print(f'{batch_size} - {metric}')\n",
        "  metrics_batch_size.append(metric)"
      ],
      "metadata": {
        "id": "v49ZX-Eu-umj"
      },
      "id": "v49ZX-Eu-umj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(batch_size_list, metrics_batch_size, color = 'red')\n",
        "plt.title('NN_accuracy', fontsize=20)\n",
        "plt.xlabel('batch_size', fontsize=15)\n",
        "plt.xscale('log')\n",
        "plt.ylabel('accuracy', fontsize=15)\n",
        "plt.legend(prop={'size': 15})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cjTsdW1x_B7j"
      },
      "id": "cjTsdW1x_B7j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Лучшее количество batch_size = 128."
      ],
      "metadata": {
        "id": "A5blokq1_HE0"
      },
      "id": "A5blokq1_HE0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### epochs"
      ],
      "metadata": {
        "id": "cLEysJPlNAFP"
      },
      "id": "cLEysJPlNAFP"
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_epochs = nn_conv(x_train, x_test, y_train, y_test, branch = 4, start_filters = 24, \n",
        "              start_kernel = 2, neurons = 2000, batch_size = 128, epochs = 30, verbose = 1, seed = 42)[1]['val_accuracy']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRPlPrDaNDJq",
        "outputId": "3df2d454-750c-4db1-aa63-e79167767aaf"
      },
      "id": "IRPlPrDaNDJq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "391/391 [==============================] - 40s 99ms/step - loss: 1.4638 - accuracy: 0.4688 - val_loss: 1.1414 - val_accuracy: 0.5962\n",
            "Epoch 2/30\n",
            "391/391 [==============================] - 38s 98ms/step - loss: 1.0138 - accuracy: 0.6412 - val_loss: 0.9531 - val_accuracy: 0.6627\n",
            "Epoch 3/30\n",
            "391/391 [==============================] - 38s 97ms/step - loss: 0.8267 - accuracy: 0.7085 - val_loss: 0.8549 - val_accuracy: 0.7088\n",
            "Epoch 4/30\n",
            "391/391 [==============================] - 38s 97ms/step - loss: 0.6991 - accuracy: 0.7556 - val_loss: 0.7912 - val_accuracy: 0.7269\n",
            "Epoch 5/30\n",
            "391/391 [==============================] - 38s 98ms/step - loss: 0.5831 - accuracy: 0.7951 - val_loss: 0.7492 - val_accuracy: 0.7431\n",
            "Epoch 6/30\n",
            "193/391 [=============>................] - ETA: 18s - loss: 0.4675 - accuracy: 0.8377"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list(range(1,11)), metrics_epochs, color = 'red')\n",
        "plt.title('NN_accuracy', fontsize=20)\n",
        "plt.xlabel('epochs', fontsize=15)\n",
        "plt.ylabel('accuracy', fontsize=15)\n",
        "plt.legend(prop={'size': 15})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XWP-SUIxNnzR"
      },
      "id": "XWP-SUIxNnzR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Но 9 эпохе нейронная сеть уже сходится. Дальнейшее обучение вызывает переобучение. Так как метрика на трейне стримится к 1."
      ],
      "metadata": {
        "id": "zG1_IOf0N_vD"
      },
      "id": "zG1_IOf0N_vD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Вывод:"
      ],
      "metadata": {
        "id": "mZa39HAbQG6b"
      },
      "id": "mZa39HAbQG6b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я постарался сделать необычную нелинейную свёрточную нейронную сеть, учитывая заканомерности изученной сети AlexNet, а точнее: сначала задаём большой размер ядра для свёртки, далее уменьшаем размер ядра свёртки, увиличиваем количество фильтров и используем связки, свёртка - пулинг. Далее выпремляем наш конечный тензор, прогоняем его через полносвязный нейронный слой и выводим на конечные 10 выходных нейронов наш ответ в вероятностном виде (от 0 до 1) с помощью функции активации softmax.\n",
        "\n",
        "Идея моей нейронной сети, чтобы на каждом этапе свёртка - пулинг, нейронная сеть вспоминала изначальные данные той же размерности, но свёрнутые ядрами разных размеров. Такая компоновка данных на каждом этапе, должна давать более интересные резуьтаты, чем обычная линейная модель.\n",
        "\n",
        "Я проэксперементировал с гиперпараметрами моей нейронной сети и сделал выводы для каждого гиперпараметра."
      ],
      "metadata": {
        "id": "dHirVozJQM22"
      },
      "id": "dHirVozJQM22"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "lesson-4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}